{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HU4eZUUggCel"
   },
   "source": [
    "# Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ih27B2XRf60E"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstring\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatasets\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtextract\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpdfminer\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import datasets\n",
    "\n",
    "import textract\n",
    "import pdfminer\n",
    "import io\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ady0V_JZgESI"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wR_8SQo3RUk"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "Dataset : https://huggingface.co/datasets/burberg92/resume_summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAImcIJttrHf",
    "outputId": "8bdb5293-7174-4481-e140-555e047613f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b06e9b67b742d8bc530e6301cf3bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/241 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to C:/Users/Alfian/.cache/huggingface/datasets/burberg92___parquet/burberg92--resume_summary-c0da54b913be772e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e77f34906834f88a697b0d834e8ef7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbec50143b804e6b8e7c47344d0c472f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/36.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d85edd7edd4422da24dfc685df650e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b1067e6329445ca3576f657066d520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:/Users/Alfian/.cache/huggingface/datasets/burberg92___parquet/burberg92--resume_summary-c0da54b913be772e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['resume', 'ex_summary'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"burberg92/resume_summary\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZL2KvCD3TeS"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wXDPIwvvsVK",
    "outputId": "732397f7-ac5b-4aa4-dec1-41d982364ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laura Anderson Product Manager\n",
      "Experience:\n",
      "Product lifecycle management, market research, and roadmap development (5 years)\n",
      "Agile methodologies and collaboration with cross-functional teams\n",
      "Education:\n",
      "Bachelor's degree in Business Administration, NOP University\n"
     ]
    }
   ],
   "source": [
    "def clean_summ(res):\n",
    "  res = res.replace(\"Resume: \",\"\")\n",
    "  res = res.replace(\"Name: \",\"\")\n",
    "  res = res.replace(\" | \",\" \")\n",
    "  res = res.replace(\"•\",\"\")\n",
    "  res = res.replace(\"_\",\"\")  \n",
    "  return res\n",
    "\n",
    "print(clean_summ(\"Resume: Laura Anderson | Product Manager\\nExperience:\\nProduct lifecycle management, market research, and roadmap development (5 years)\\nAgile methodologies and collaboration with cross-functional teams\\nEducation:\\nBachelor's degree in Business Administration, NOP University\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "c4ZLwveSu-Vf",
    "outputId": "8148c3ba-9dcd-49f1-ce8b-55e014ca2952"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume</th>\n",
       "      <th>ex_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resume: Laura Anderson | Product Manager\\nExpe...</td>\n",
       "      <td>Results-driven Product Manager with 5 years of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resume: Steven Thompson | Operations Manager\\n...</td>\n",
       "      <td>Efficient Operations Manager with 8 years of e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linda Harris | Event Planner\\nExperience:\\nEve...</td>\n",
       "      <td>Detail-oriented Event Planner with 6 years of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Clark | Customer Service Representativ...</td>\n",
       "      <td>Customer-focused Customer Service Representati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carol Martinez | Content Writer\\nExperience:\\n...</td>\n",
       "      <td>Creative Content Writer with 5 years of experi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              resume  \\\n",
       "0  Resume: Laura Anderson | Product Manager\\nExpe...   \n",
       "1  Resume: Steven Thompson | Operations Manager\\n...   \n",
       "2  Linda Harris | Event Planner\\nExperience:\\nEve...   \n",
       "3  Michael Clark | Customer Service Representativ...   \n",
       "4  Carol Martinez | Content Writer\\nExperience:\\n...   \n",
       "\n",
       "                                          ex_summary  \n",
       "0  Results-driven Product Manager with 5 years of...  \n",
       "1  Efficient Operations Manager with 8 years of e...  \n",
       "2  Detail-oriented Event Planner with 6 years of ...  \n",
       "3  Customer-focused Customer Service Representati...  \n",
       "4  Creative Content Writer with 5 years of experi...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['resume'] = dataset['resume']\n",
    "df['ex_summary'] = dataset['ex_summary']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KPMdVq9Du9JW"
   },
   "outputs": [],
   "source": [
    "df['resume_clean'] = df['resume'].apply(clean_summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "V8CMc6n2vG53",
    "outputId": "08af66ab-c137-4728-df43-e7f6310dd8ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume</th>\n",
       "      <th>ex_summary</th>\n",
       "      <th>resume_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resume: Laura Anderson | Product Manager\\nExpe...</td>\n",
       "      <td>Results-driven Product Manager with 5 years of...</td>\n",
       "      <td>Laura Anderson Product Manager\\nExperience:\\nP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resume: Steven Thompson | Operations Manager\\n...</td>\n",
       "      <td>Efficient Operations Manager with 8 years of e...</td>\n",
       "      <td>Steven Thompson Operations Manager\\nExperience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linda Harris | Event Planner\\nExperience:\\nEve...</td>\n",
       "      <td>Detail-oriented Event Planner with 6 years of ...</td>\n",
       "      <td>Linda Harris Event Planner\\nExperience:\\nEvent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Clark | Customer Service Representativ...</td>\n",
       "      <td>Customer-focused Customer Service Representati...</td>\n",
       "      <td>Michael Clark Customer Service Representative\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carol Martinez | Content Writer\\nExperience:\\n...</td>\n",
       "      <td>Creative Content Writer with 5 years of experi...</td>\n",
       "      <td>Carol Martinez Content Writer\\nExperience:\\nCo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              resume  \\\n",
       "0  Resume: Laura Anderson | Product Manager\\nExpe...   \n",
       "1  Resume: Steven Thompson | Operations Manager\\n...   \n",
       "2  Linda Harris | Event Planner\\nExperience:\\nEve...   \n",
       "3  Michael Clark | Customer Service Representativ...   \n",
       "4  Carol Martinez | Content Writer\\nExperience:\\n...   \n",
       "\n",
       "                                          ex_summary  \\\n",
       "0  Results-driven Product Manager with 5 years of...   \n",
       "1  Efficient Operations Manager with 8 years of e...   \n",
       "2  Detail-oriented Event Planner with 6 years of ...   \n",
       "3  Customer-focused Customer Service Representati...   \n",
       "4  Creative Content Writer with 5 years of experi...   \n",
       "\n",
       "                                        resume_clean  \n",
       "0  Laura Anderson Product Manager\\nExperience:\\nP...  \n",
       "1  Steven Thompson Operations Manager\\nExperience...  \n",
       "2  Linda Harris Event Planner\\nExperience:\\nEvent...  \n",
       "3  Michael Clark Customer Service Representative\\...  \n",
       "4  Carol Martinez Content Writer\\nExperience:\\nCo...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjHRXfC6j5lC"
   },
   "source": [
    "# FineTune BART Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDat1uRdivZ6",
    "outputId": "fa177be4-d7fd-4f5a-830f-8d2baeb0c9d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-large-cnn.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qL2cyDLZyj4l"
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4fAYTUvyl4e"
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(df['resume_clean'].values.tolist(), max_length=512, padding=\"max_length\", return_tensors=\"tf\").input_ids\n",
    "labels = tokenizer(df['ex_summary'].values.tolist(), max_length=128, padding=\"max_length\", return_tensors=\"tf\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhBfJkGd4_Bh",
    "outputId": "fa4aa981-2652-4659-d3a0-7c7411de2711"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMEzXhbhv5L7",
    "outputId": "e43bcee1-361e-4791-cc67-67265d5f842a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bart_for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (TFBartMainLayer)     multiple                  406290432 \n",
      "                                                                 \n",
      " final_logits_bias (BiasLaye  multiple                 50264     \n",
      " r)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 406,340,696\n",
      "Trainable params: 406,290,432\n",
      "Non-trainable params: 50,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kkdtUMVw0tA",
    "outputId": "9ba6d472-8b61-4e18-9514-6dee08e9679d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 157s 1s/step - loss: 0.1946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbe11afbe50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "num_epochs = 1\n",
    "batch_size = 4\n",
    "\n",
    "model.compile(optimizer=Adam(5e-5))\n",
    "model.fit(x=inputs, y=labels,epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "FCUPCHSQFtdu"
   },
   "outputs": [],
   "source": [
    "test = \"Alice Clark  AI / Machine Learning    Delhi, India Email me on Indeed  •  20+ years of experience in data handling, design, and development  •  Data Warehouse: Data analysis, star/snow flake scema data modelling and design specific to  data warehousing and business intelligence  •  Database: Experience in database designing, scalability, back-up and recovery, writing and  optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes.  Cloud platform: Worked on Microsoft Azure cloud services like Document DB, SQL Azure,  Stream Analytics, Event hub, Power BI, Web Job, Web App, Power BI, Azure data lake  analytics(U-SQL)  Willing to relocate anywhere    WORK EXPERIENCE  Software Engineer  Microsoft – Bangalore, Karnataka  January 2000 to Present  1. Microsoft Rewards Live dashboards:  Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping  online. Microsoft Rewards members can earn points when searching with Bing, browsing with  Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft  Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft  rewards website. Rewards live dashboards gives a live picture of usage world-wide and by  markets like US, Canada, Australia, new user registration count, top/bottom performing rewards  offers, orders stats and weekly trends of user activities, orders and new user registrations. the  PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.  Technology/Tools used    EDUCATION  Indian Institute of Technology – Mumbai  2001    SKILLS  Machine Learning, Natural Language Processing, and Big Data Handling    ADDITIONAL INFORMATION  Professional Skills  • Excellent analytical, problem solving, communication, knowledge transfer and interpersonal  skills with ability to interact with individuals at all the levels  • Quick learner and maintains cordial relationship with project manager and team members and  good performer both in team and independent job environments  • Positive attitude towards superiors &amp; peers  • Supervised junior developers throughout project lifecycle and provided technical assistance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "VXHr5lbm89WW"
   },
   "outputs": [],
   "source": [
    "test_1 = tokenizer(test, max_length=512, padding=\"max_length\", return_tensors=\"tf\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zaxpYJFc9NDM",
    "outputId": "e23bb8ef-d019-4c1c-ffb3-7c79c96d591f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\talentease\\lib\\site-packages\\transformers\\generation\\tf_utils.py:854: UserWarning: Using `max_length`'s default (142) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5wi-fki9SPS",
    "outputId": "24ab3b40-afe0-4a11-b2ef-61a5084dd2d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical AI / Machine Learning Software Engineer with 20+ years of experience in data handling, design, and development. Skilled in database designing, scalability, back-up and recovery, writing and optimizing SQL code and Stored Procedures, creating functions, views, triggers and indexes, with experience in Document DB, SQL Azure,  Stream Analytics, Event hub, Power BI, Web Job, Web App, and Power BI. Holds a Bachelor's degree in Machine Learning from IJST University.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UwGUWPegHvKZ",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MissingFileError",
     "evalue": "The file \"/Muhammad Alfian Pratama new resume.pdf\" can not be found.\nIs this the right path/to/file/you/want/to/extract.pdf?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMissingFileError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n\u001b[1;32m----> 5\u001b[0m text\u001b[39m=\u001b[39mextract_text_from_pdf(\u001b[39m'\u001b[39;49m\u001b[39m/Muhammad Alfian Pratama new resume.pdf\u001b[39;49m\u001b[39m'\u001b[39;49m)   \u001b[39m# Enter the path to the resume here\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m, in \u001b[0;36mextract_text_from_pdf\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_text_from_pdf\u001b[39m(file_path):\n\u001b[1;32m----> 2\u001b[0m     text \u001b[39m=\u001b[39m textract\u001b[39m.\u001b[39;49mprocess(file_path, method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpdfminer\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\talentease\\lib\\site-packages\\textract\\parsers\\__init__.py:41\u001b[0m, in \u001b[0;36mprocess\u001b[1;34m(filename, input_encoding, output_encoding, extension, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39m# make sure the filename exists\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(filename):\n\u001b[1;32m---> 41\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mMissingFileError(filename)\n\u001b[0;32m     43\u001b[0m \u001b[39m# get the filename extension, which is something like .docx for\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m# example, and import the module dynamically using importlib. This\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[39m# is a relative import so the name of the package is necessary\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[39m# normally, file extension will be extracted from the file name\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m# if the file name has no extension, then the user can pass the\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39m# extension as an argument\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39mif\u001b[39;00m extension:\n",
      "\u001b[1;31mMissingFileError\u001b[0m: The file \"/Muhammad Alfian Pratama new resume.pdf\" can not be found.\nIs this the right path/to/file/you/want/to/extract.pdf?"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    text = textract.process(file_path, method='pdfminer')\n",
    "    text = text.decode('utf-8')\n",
    "    return text\n",
    "text=extract_text_from_pdf('/Muhammad Alfian Pratama new resume.pdf')   # Enter the path to the resume here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txQ7gT4GIFZu"
   },
   "outputs": [],
   "source": [
    "test_2 = tokenizer(text, max_length=512, padding=\"max_length\", return_tensors=\"tf\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GqZYzwQIO1c"
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(test_2,min_length=50, max_length=150,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hy4-Z-lNIZPk",
    "outputId": "0176aeaa-956f-4410-d190-bbd13a09abeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical Data Scientist with expertise in Data Science and Machine Learning. Proficient in Python and R programming languages, and proficient in TensorFlow and Flask. Holds a Bachelor of Data Science degree from FTMM Universitas Airlangga.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUkznaBCPMB3"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained('/content/drive/MyDrive/cv model/cv_summarization_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCWATSamT13_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e0b1403b614d839ffa0017b4a2af00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29c90d9463949178915ed4e7bd60ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at walkerrose/cv_summarization-distilbart-cnn-16-6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0547e32afaad48cfb002838aa12033a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/358 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa681a83f90445bb47fb71fae2a6ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.33k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9d04287b9c4f79a21a4a760a9505b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b97885676641af81365b269dec64ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80aa007c9c934775b18b04986bdb580d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94abb41e5b824c44a7bc6fa353fefead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TFBartForConditionalGeneration, AutoTokenizer\n",
    "# Replace with your custom model of choice\n",
    "model = TFBartForConditionalGeneration.from_pretrained('walkerrose/cv_summarization-distilbart-cnn-16-6')\n",
    "tokenizer = AutoTokenizer.from_pretrained('walkerrose/cv_summarization-distilbart-cnn-16-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'Govardhana K Senior Software Engineer  Bengaluru, Karnataka, Karnataka - Email me on Indeed: indeed.com/r/Govardhana-K/ b2de315d95905b68  Total IT experience 5 Years 6 Months Cloud Lending Solutions INC 4 Month • Salesforce Developer Oracle 5 Years 2 Month • Core Java Developer Languages Core Java, Go Lang Oracle PL-SQL programming, Sales Force Developer with APEX.  Designations & Promotions  Willing to relocate: Anywhere  WORK EXPERIENCE  Senior Software Engineer  Cloud Lending Solutions -  Bangalore, Karnataka -  January 2018 to Present  Present  Senior Consultant  Oracle -  Bangalore, Karnataka -  November 2016 to December 2017  Staff Consultant  Oracle -  Bangalore, Karnataka -  January 2014 to October 2016  Associate Consultant  Oracle -  Bangalore, Karnataka -  November 2012 to December 2013  EDUCATION  B.E in Computer Science Engineering  Adithya Institute of Technology -  Tamil Nadu  September 2008 to June 2012  https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN https://www.indeed.com/r/Govardhana-K/b2de315d95905b68?isid=rex-download&ikw=download-top&co=IN   SKILLS  APEX. (Less than 1 year), Data Structures (3 years), FLEXCUBE (5 years), Oracle (5 years), Algorithms (3 years)  LINKS  https://www.linkedin.com/in/govardhana-k-61024944/  ADDITIONAL INFORMATION  Technical Proficiency:  Languages: Core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, Sales Force with APEX. Tools: RADTool, Jdeveloper, NetBeans, Eclipse, SQL developer, PL/SQL Developer, WinSCP, Putty Web Technologies: JavaScript, XML, HTML, Webservice  Operating Systems: Linux, Windows Version control system SVN & Git-Hub Databases: Oracle Middleware: Web logic, OC4J Product FLEXCUBE: Oracle FLEXCUBE Versions 10.x, 11.x and 12.x  https://www.linkedin.com/in/govardhana-k-61024944/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = tokenizer(test, padding=\"max_length\", return_tensors=\"tf\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(test_2,min_length=50, max_length=150,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experienced Senior Software Engineer with 5 years of experience in core Java, Go Lang, Data Structures & Algorithms, Oracle PL-SQL programming, and OC4J Product FLEXCUBE. Holds a B.E in Computer Science Engineering from Tamil Nadu.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required modules\n",
    "import PyPDF2\n",
    "\n",
    "# creating a pdf reader object\n",
    "reader = PyPDF2.PdfReader(\"Muhammad Alfian Pratama new resume.pdf\")\n",
    "text = reader.pages[0].extract_text()\n",
    "\n",
    "text = clean_summ(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Muhammad Alfian Pratama  \\n LinkedIn    +62-855-2078 -1007     alfianp613.github.io     alfianp613@gmail.com      GitHub  \\nI’m a 6th semester student curious and interested in Data Science and Machine Learning . I possess advanced proficiency in Python and \\nR programming languages, and I have honed my skills in prominent frameworks such as TensorFlow and Flask. I am currently seek ing an \\nopportunity to expand and apply my skills through a one semester industry plac ement, with a particular focus on data -related roles. I \\nam eager to delve deeper into the practical aspects of the field and gain invaluable real -world experience.  \\n \\nSkills      \\n \\n   Python R HTML CSS Javascript Tableau Microsoft Excel Flask Tensorflow SPSS Minitab MySQL NoSQL Fire base  \\n   Machine Learning Data Science Data Analytics Statistics Microservices Backend English  \\nEducation     \\nMachine Learning Learning Path   Bangkit  Academy 2023 By Google, \\nGoTo, & Traveloka  Indonesia  02/2023 - Current  \\n “Magang dan Studi Independen Bersertifikat” Batch 4 held by Kemendikbud RI  \\n Student with Ahead of Schedule Status  \\n Accomplish 6 Specialization Courses from Coursera such as Google Data Analytics, Google IT Automation, Mathematics for Machin e Learning \\nSpecialization, Machine Learning Specialization, DeepLearning.AI TensorFlow Developer Specialization, and TensorFlow: Da ta and Deployment \\nSpecialization  \\nBachelor of Data Science   Universitas Airlangga  Surabaya , Indonesia  09/2020 - Current  \\n Major in Data Science Technology  (GPA 3.88/4) . \\n 3rd most outstanding FTMM Universitas Airlangga Student  \\n Related Courses: Programming Algorithm, Calculus, Linear Algebra, Parametric Statistics, Non Parametric Statistics, Probabilit y, Computational \\nStatistics,  Mathematical Statistics, Multivariate Statistics, Stochastic Process, Survival Analysis, Data Min ing, Natural Language Processing, \\nDatabases, Spatial Data   Analysis.  \\nWork Experience    \\nLaboratory Assistant   FTMM Universitas Airlangga  Surabaya , Indonesia  03/2022 - 07/2022  \\n Laboratory Assistant for Programming Algorithm course s. \\n Assisted Lecturer for scoring practice modules and mentoring for 25 students  \\n \\nProjects     \\nBicara Pilpres ( Sentiment Analysis Dashboard for Indonesian Presidential \\nElection 2024 Candidates ) Surabaya, Indonesia  12/2022 - 01/2023  \\n Led the end-to-end development process such as front -end design, software architecture, machine learning model, pipeline.  \\n Successfully implemented a microservices architecture, utilizing Python Flask for the main website backend and machine learni ng API, to enhanc e \\nthe scalability and efficiency of the web application.  Also, implemented Firebase to store data using Firebase Firestore Database (NoSQL) and \\nFirebase Storage.  \\n Implemented deployment of the web application on Digital Ocean Droplets, configuring SSL certi fication and domain integration using Nginx.  \\nAchieved secure and reliable web hosting, ensuring optimal performance and user experience.  \\n Implemented Progressive Web Application (PWA) for better user experience.  \\n This project got Top 50 Hackfest 2023 held by  GDSC Indonesia.  \\nSIBI (Sistem Bahasa Isyarat  Indonesai) Sign Language Alphabetic \\nClassification using Mediapipe  Surabaya, Indonesia  11/2022 - 12/2022  \\n Implemented Tensorflow Data Generator for augmenting data to reproduce primary data.  \\n Utilized the power of Mediapipe to effectively extract hand landmark points, enabling the training of a cutting -edge machine learning model and \\nthe development of real -time detection capabilities.  \\n Achieving 94% accuracy on training data and 90% accuracy on  testing data.  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = tokenizer(text, padding=\"max_length\", return_tensors=\"np\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(test_2,min_length=50, max_length=150,early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Talented Data Science Student with expertise in Python R HTML CSS Javascript Tableau and TensorFlow. Holds a Bachelor of Data Science Technology with a focus on data-related roles. Proficient in a variety of data analysis tools, including Stochastic Process, Survival Analysis, Natural Language Processing, and Spatial Data Analysis. Hold a Bachelor's degree in Computer Science from Universitas Airlangga.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBartForConditionalGeneration.\n",
      "\n",
      "All the layers of TFBartForConditionalGeneration were initialized from the model checkpoint at walkerrose/cv_summarization-distilbart-cnn-16-6.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBartForConditionalGeneration, AutoTokenizer\n",
    "# Replace with your custom model of choice\n",
    "model = TFBartForConditionalGeneration.from_pretrained('walkerrose/cv_summarization-distilbart-cnn-16-6')\n",
    "tokenizer = AutoTokenizer.from_pretrained('walkerrose/cv_summarization-distilbart-cnn-16-6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_summ(res):\n",
    "  res = res.replace(\"Resume: \",\"\")\n",
    "  res = res.replace(\"Name: \",\"\")\n",
    "  res = res.replace(\" | \",\" \")\n",
    "  res = res.replace(\"•\",\"\")\n",
    "  res = res.replace(\"_\",\"\")  \n",
    "  res = res.strip().replace('\\n', '')\n",
    "  res = re.sub(' +', ' ', res)\n",
    "  res = re.sub(r'\\●', ' ', res)\n",
    "  return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required modules\n",
    "import PyPDF2\n",
    "\n",
    "# creating a pdf reader object\n",
    "reader = PyPDF2.PdfReader(\"Muhammad Alfian Pratama new resume.pdf\")\n",
    "text = reader.pages[0].extract_text()\n",
    "\n",
    "text = clean_summ(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4597"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"MUHAMMAD RAZAN FAWWAZ\n",
    "+6285397946743 | m_razan@mhs.unsyiah.ac.id | https://linkedin.com/in/razanfawwaz\n",
    "https://razanfawwaz.xyz | https://github.com/razanfawwaz | Banda Aceh\n",
    "EDUCATION\n",
    "UNIVERSITAS SYIAH KUALA Sep 2020 - Sep 2024\n",
    "Informatics (Expected)\n",
    "● The Most Outstanding Student III from the Faculty of Natural Sciences and Mathematics Universitas Syiah\n",
    "Kuala.\n",
    "● Lab assistant of Web Programming odd semester class. Teach 49 students basic Web Programming including\n",
    "Laravel, TailwindCSS, Github, Conventional Commit, and Deployment.\n",
    "BANGKIT ACADEMY LED BY GOOGLE, GOTO, TRAVELOKA Feb 2023 - Jul 2023\n",
    "Cloud Computing\n",
    "● Actively engaged in discussions and provided assistance on various platforms, including meet sessions and\n",
    "Discord channels.\n",
    "● Contributed to the development of a backend system for the capstone project, utilizing technologies such as\n",
    "Express, Firebase, and Node.js\n",
    "● Demonstrated leadership skills by leading the capstone team, coordinating efforts, and ensuring successful\n",
    "project completion\n",
    "● Shared knowledge and insights about Cloud Run with study group members, fostering a collaborative learning\n",
    "environment\n",
    "EXPERIENCES\n",
    "GOOGLE DEVELOPER STUDENT CLUBS - UNIVERSITAS SYIAH KUALA\n",
    "Chapter Lead Aug 2022 - Present\n",
    "● Lead a community of 200 members, organizing and hosting 8 successful events and driving a 200% increase in\n",
    "social media followers.\n",
    "GOOGLE DEVELOPER STUDENT CLUBS INDONESIA\n",
    "Lead/Person in Charge Nov 2022 - Mar 2023\n",
    "● Expanded the reach of HackFest 2023 by registering teams by chapters, achieving a 625% growth compared to the\n",
    "previous year.\n",
    "● Gained a remarkable growth of registered teams by 1460% than the previous year, an outreach of 2.995%, and an\n",
    "18.9% growth in followers, while actively engaging up to 526% of accounts on Instagram.\n",
    "● Organized and executed the event both online and offline, ensuring maximum participation and successful\n",
    "outcomes.\n",
    "BERSINAR\n",
    "Co-Founder Dec 2020 - Present\n",
    "Head of Product Engineering Jan 2023 - Present\n",
    "● Initiated Bersinar in 2020, helped more than 15.000 Senior High Schools students, and made 90% of customers\n",
    "satisfied with #BersinarMengajar products.\n",
    "● Contributed to creating Bersinar landing page using ReactJS in 3 months of development.\n",
    "● Directed the Operational team to collaborate with the Academic division and Tutors to operate Zoom meetings\n",
    "for at least 40 classes per month.\n",
    "● Implemented URL Shortener with Bersinar domain and gained over 80% unique URLs in the last 30 days.\n",
    "PROJECTS\n",
    "● Charum-Backend: Involved in a team of two to develop a backend using Golang and the Echo framework, with\n",
    "MongoDB as the database, also JWT for authentication.\n",
    "● Go-Shortener: Developed a URL shortener using Golang, the Echo framework, MySQL, and GORM. Applied\n",
    "clean architecture principles for maintainability and scalability. Utilized Docker for containerization and\n",
    "deployment.\n",
    "● Study Case - GovTechEdu: Contributed as a student to finish the task from the study case by GovTech Edu and\n",
    "attended the Mock Interview.\n",
    "● Thalassic 2022 Website: Developed a website for Thalassic SMA 28 Jakarta, working together with\n",
    "ZeroFourthStudio.\n",
    "● MagangMerdeka Website (2022): Created MagangMerdeka website that provide the data from API Kampus\n",
    "Merdeka using NextJS and TailwindCSS. Total users in June increased more than 400% in the last 30 days.\n",
    "ACHIEVEMENTS\n",
    "● The Most Outstanding Student III from FMIPA Universitas Syiah Kuala Mar 2023\n",
    "● Top 10 among 162 teams in Start-Up Academy held by COMPFEST Aug 2021\n",
    "SKILLS\n",
    "● Technical: Golang, Echo, MySQL, MongoDB, Firebase, Javascript, ReactJS, JavaScript, GCP, Clou\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = clean_summ(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3518"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MUHAMMAD RAZAN FAWWAZ+6285397946743 mrazan@mhs.unsyiah.ac.id https://linkedin.com/in/razanfawwazhttps://razanfawwaz.xyz https://github.com/razanfawwaz Banda AcehEDUCATIONUNIVERSITAS SYIAH KUALA Sep 2020 - Sep 2024Informatics (Expected)  The Most Outstanding Student III from the Faculty of Natural Sciences and Mathematics Universitas SyiahKuala.  Lab assistant of Web Programming odd semester class. Teach 49 students basic Web Programming includingLaravel, TailwindCSS, Github, Conventional Commit, and Deployment.BANGKIT ACADEMY LED BY GOOGLE, GOTO, TRAVELOKA Feb 2023 - Jul 2023Cloud Computing  Actively engaged in discussions and provided assistance on various platforms, including meet sessions andDiscord channels.  Contributed to the development of a backend system for the capstone project, utilizing technologies such asExpress, Firebase, and Node.js  Demonstrated leadership skills by leading the capstone team, coordinating efforts, and ensuring successfulproject completion  Shared knowledge and insights about Cloud Run with study group members, fostering a collaborative learningenvironmentEXPERIENCESGOOGLE DEVELOPER STUDENT CLUBS - UNIVERSITAS SYIAH KUALAChapter Lead Aug 2022 - Present  Lead a community of 200 members, organizing and hosting 8 successful events and driving a 200% increase insocial media followers.GOOGLE DEVELOPER STUDENT CLUBS INDONESIALead/Person in Charge Nov 2022 - Mar 2023  Expanded the reach of HackFest 2023 by registering teams by chapters, achieving a 625% growth compared to theprevious year.  Gained a remarkable growth of registered teams by 1460% than the previous year, an outreach of 2.995%, and an18.9% growth in followers, while actively engaging up to 526% of accounts on Instagram.  Organized and executed the event both online and offline, ensuring maximum participation and successfuloutcomes.BERSINARCo-Founder Dec 2020 - PresentHead of Product Engineering Jan 2023 - Present  Initiated Bersinar in 2020, helped more than 15.000 Senior High Schools students, and made 90% of customerssatisfied with #BersinarMengajar products.  Contributed to creating Bersinar landing page using ReactJS in 3 months of development.  Directed the Operational team to collaborate with the Academic division and Tutors to operate Zoom meetingsfor at least 40 classes per month.  Implemented URL Shortener with Bersinar domain and gained over 80% unique URLs in the last 30 days.PROJECTS  Charum-Backend: Involved in a team of two to develop a backend using Golang and the Echo framework, withMongoDB as the database, also JWT for authentication.  Go-Shortener: Developed a URL shortener using Golang, the Echo framework, MySQL, and GORM. Appliedclean architecture principles for maintainability and scalability. Utilized Docker for containerization anddeployment.  Study Case - GovTechEdu: Contributed as a student to finish the task from the study case by GovTech Edu andattended the Mock Interview.  Thalassic 2022 Website: Developed a website for Thalassic SMA 28 Jakarta, working together withZeroFourthStudio.  MagangMerdeka Website (2022): Created MagangMerdeka website that provide the data from API KampusMerdeka using NextJS and TailwindCSS. Total users in June increased more than 400% in the last 30 days.ACHIEVEMENTS  The Most Outstanding Student III from FMIPA Universitas Syiah Kuala Mar 2023  Top 10 among 162 teams in Start-Up Academy held by COMPFEST Aug 2021SKILLS  Technical: Golang, Echo, MySQL, MongoDB, Firebase, Javascript, ReactJS, JavaScript, GCP, Clou'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split(\" \")[0:600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer, framework=\"tf\")\n",
    "\n",
    "hasil = summarizer(text,min_length=50,max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experienced student with expertise in Golang, Echo, MySQL, JavaScript, and Clouc.js. Demonstrated leadership skills by leading the capstone team, coordinating efforts, and ensuring successful project completion. Developed a URL shortener using Golang and the Echo framework, withMongoDB as the database, also JWT for authentication.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "00d6bfbf0318ea386fca9a6f1e34e89dfe01dc0d94f309c9fa2c9daa7692de77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
